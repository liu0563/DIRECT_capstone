{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get Long/Lat Data from Tweets\n",
    "\n",
    "-  Data pulled using AppAuth Handler through Tweepy \n",
    "-  Search Query \"Climate Change\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sarahalamdari/Desktop/github/DIRECT_capstone/examples\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../wyns/data/tweets.txt\",  lines=True)  # json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contributors', 'coordinates', 'created_at', 'display_text_range', 'entities', 'extended_entities', 'favorite_count', 'favorited', 'full_text', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata', 'place', 'possibly_sensitive', 'quoted_status', 'quoted_status_id', 'quoted_status_id_str', 'retweet_count', 'retweeted', 'retweeted_status', 'source', 'truncated', 'user', 'withheld_in_countries']\n"
     ]
    }
   ],
   "source": [
    "#  Check dictionary keys\n",
    "\n",
    "print (list(df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus contains 89688 tweets\n"
     ]
    }
   ],
   "source": [
    "print (\"Corpus contains {0} tweets\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127      {'contained_within': [], 'url': 'https://api.t...\n",
      "191      {'contained_within': [], 'url': 'https://api.t...\n",
      "370      {'contained_within': [], 'url': 'https://api.t...\n",
      "574      {'contained_within': [], 'url': 'https://api.t...\n",
      "589      {'contained_within': [], 'url': 'https://api.t...\n",
      "612      {'contained_within': [], 'url': 'https://api.t...\n",
      "632      {'contained_within': [], 'url': 'https://api.t...\n",
      "712      {'contained_within': [], 'url': 'https://api.t...\n",
      "927      {'contained_within': [], 'url': 'https://api.t...\n",
      "986      {'contained_within': [], 'url': 'https://api.t...\n",
      "1395     {'contained_within': [], 'url': 'https://api.t...\n",
      "1401     {'contained_within': [], 'url': 'https://api.t...\n",
      "1441     {'contained_within': [], 'url': 'https://api.t...\n",
      "1449     {'contained_within': [], 'url': 'https://api.t...\n",
      "1490     {'contained_within': [], 'url': 'https://api.t...\n",
      "1541     {'contained_within': [], 'url': 'https://api.t...\n",
      "1559     {'contained_within': [], 'url': 'https://api.t...\n",
      "1780     {'contained_within': [], 'url': 'https://api.t...\n",
      "1927     {'contained_within': [], 'url': 'https://api.t...\n",
      "2160     {'contained_within': [], 'url': 'https://api.t...\n",
      "2280     {'contained_within': [], 'url': 'https://api.t...\n",
      "2376     {'contained_within': [], 'url': 'https://api.t...\n",
      "2453     {'contained_within': [], 'url': 'https://api.t...\n",
      "2456     {'contained_within': [], 'url': 'https://api.t...\n",
      "2484     {'contained_within': [], 'url': 'https://api.t...\n",
      "2485     {'contained_within': [], 'url': 'https://api.t...\n",
      "2530     {'contained_within': [], 'url': 'https://api.t...\n",
      "2562     {'contained_within': [], 'url': 'https://api.t...\n",
      "2570     {'contained_within': [], 'url': 'https://api.t...\n",
      "2710     {'contained_within': [], 'url': 'https://api.t...\n",
      "                               ...                        \n",
      "86776    {'contained_within': [], 'url': 'https://api.t...\n",
      "86821    {'contained_within': [], 'url': 'https://api.t...\n",
      "86859    {'contained_within': [], 'url': 'https://api.t...\n",
      "86875    {'contained_within': [], 'url': 'https://api.t...\n",
      "86945    {'contained_within': [], 'url': 'https://api.t...\n",
      "87024    {'contained_within': [], 'url': 'https://api.t...\n",
      "87158    {'contained_within': [], 'url': 'https://api.t...\n",
      "87271    {'contained_within': [], 'url': 'https://api.t...\n",
      "87276    {'contained_within': [], 'url': 'https://api.t...\n",
      "87324    {'contained_within': [], 'url': 'https://api.t...\n",
      "87333    {'contained_within': [], 'url': 'https://api.t...\n",
      "87424    {'contained_within': [], 'url': 'https://api.t...\n",
      "87441    {'contained_within': [], 'url': 'https://api.t...\n",
      "87477    {'contained_within': [], 'url': 'https://api.t...\n",
      "87554    {'contained_within': [], 'url': 'https://api.t...\n",
      "87621    {'contained_within': [], 'url': 'https://api.t...\n",
      "87678    {'contained_within': [], 'url': 'https://api.t...\n",
      "87711    {'contained_within': [], 'url': 'https://api.t...\n",
      "87847    {'contained_within': [], 'url': 'https://api.t...\n",
      "88111    {'contained_within': [], 'url': 'https://api.t...\n",
      "88115    {'contained_within': [], 'url': 'https://api.t...\n",
      "88532    {'contained_within': [], 'url': 'https://api.t...\n",
      "88719    {'contained_within': [], 'url': 'https://api.t...\n",
      "88870    {'contained_within': [], 'url': 'https://api.t...\n",
      "88906    {'contained_within': [], 'url': 'https://api.t...\n",
      "88989    {'contained_within': [], 'url': 'https://api.t...\n",
      "89087    {'contained_within': [], 'url': 'https://api.t...\n",
      "89226    {'contained_within': [], 'url': 'https://api.t...\n",
      "89325    {'contained_within': [], 'url': 'https://api.t...\n",
      "89659    {'contained_within': [], 'url': 'https://api.t...\n",
      "Name: place, Length: 821, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df['place'].dropna())\n",
    "print (df['place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007359932944003074\n",
      "RT @NatGeo: For the Marshall Islands, climate change isn't some distant, future danger: It's already wreaking havoc. https://t.co/juuru9xc61\n"
     ]
    }
   ],
   "source": [
    "print (df['id'][0])\n",
    "print (df['full_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets found:  64312\n"
     ]
    }
   ],
   "source": [
    "# Check if Wes' Code catches all tweet text \n",
    "\n",
    "full_text = []\n",
    "i = 0\n",
    "with open(\"../wyns/data/tweets.txt\") as f:\n",
    "    for line in f:\n",
    "        b = json.loads(line)\n",
    "#         for key in b['retweeted_status'].keys():\n",
    "#             print(key)\n",
    "        if 'retweeted_status' in b:\n",
    "            if 'extended_tweet' in b['retweeted_status']:\n",
    "              #  print(b['retweeted_status']['extended_tweet']['full_text'])\n",
    "                full_text.append(b['retweeted_status']['extended_tweet']['full_text'])\n",
    "                #retweeted status -> usr -> location \n",
    "            else:\n",
    "              #  print(b['text'])\n",
    "                full_text.append(b['full_text'])\n",
    "        elif 'extended_tweet' in b:\n",
    "           # print(b['extended_tweet']['full_text'])\n",
    "            full_text.append(b['extended_tweet']['full_text'])\n",
    "        elif 'text' in b:\n",
    "           # print(b['text'])\n",
    "            full_text.append(b['full_text'])\n",
    "\n",
    "        #print(i)\n",
    "        i += 1\n",
    "#         break\n",
    "print('Tweets found: ',len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @watspn1013: Scott Pruit, Director of EPA received a 3,000 page paper with 10,000 footnotes providing documentation of his stance that c…\n"
     ]
    }
   ],
   "source": [
    "#Long/Lat Format\n",
    "\n",
    "#print (df['place'][29]['bounding_box']['coordinates'][0][0][1])\n",
    "#print (df['place'].dropna())\n",
    "#print (df['place'][8073])\n",
    "#print (df['geo'].dropna()[8073]['coordinates'][0])\n",
    "#print (df['truncated'])\n",
    "\n",
    "print (df['full_text'][64009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(874, 5)\n"
     ]
    }
   ],
   "source": [
    "#  Try saving data to 2D array [coordinate, date, full_text]\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"../wyns/data/tweets.txt\") as f:\n",
    "    for line in f:\n",
    "        b = json.loads(line) \n",
    "        if b['full_text'] != data:\n",
    "            if b['geo'] is not None:  # Checks to see if any coord data was saved in geo\n",
    "                data.append([b['geo']['coordinates'][0],\n",
    "                             b['geo']['coordinates'][1],\n",
    "                             b['place']['full_name'],\n",
    "                             b['created_at'], \n",
    "                             b['full_text']])\n",
    "            elif b['place'] is not None: # Checks to see if any coord data saved in place \n",
    "                data.append([b['place']['bounding_box']['coordinates'][0][0][0],\n",
    "                             b['place']['bounding_box']['coordinates'][0][0][1],\n",
    "                             b['place']['full_name'],\n",
    "                             b['created_at'],\n",
    "                             b['full_text']])\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "print(np.array(data).shape)\n",
    "sample = np.array(data)\n",
    "#print (sample[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-73.946553' '41.168161' 'Croton-on-Hudson, NY'\n",
      "  'Thu Jun 14 20:23:39 +0000 2018'\n",
      "  'As a pundit once said: “Gravity isn’t just a suggestion, it’s the law.”\\n\\nGovernment can try to make it illegal for staff to discuss climate change - but natural laws don’t pay attention to executive orders - or to the profits of fossil fuel companies.\\n\\n@NickyTheKat @BXEAction https://t.co/Z7mKbsjTIw']\n",
      " ['-74.026675' '40.683935' 'Manhattan, NY' 'Thu Jun 14 20:19:59 +0000 2018'\n",
      "  'Thanks for raising this topic for attention and helping us to include it in our climate change agendas. https://t.co/9JINovMthk']\n",
      " ['10.5922629' '55.1365705' 'Sweden' 'Thu Jun 14 20:09:43 +0000 2018'\n",
      "  'We’re simulation the onslaught of climate change in subarctic tundra with litter and nutient additions. Year 2 applications are now administered #soilmicrobes #climatescience #microbialecology #primingeffect #fieldwork #Abisko https://t.co/OTa41puRqG']\n",
      " ['-79.509317' '44.016826' 'Newmarket, Ontario'\n",
      "  'Thu Jun 14 19:57:14 +0000 2018'\n",
      "  '@DavidPatersonca And what is Conservatives plan to tackle climate change or did I somehow miss it?']\n",
      " ['-87.634643' '24.396308' 'Florida, USA' 'Thu Jun 14 19:56:27 +0000 2018'\n",
      "  '@realDonaldTrump BTW:can you feel the heat yet? Climate change is real #gigilovemusic']\n",
      " ['-71.524629' '41.358887' 'Narragansett, RI'\n",
      "  'Thu Jun 14 19:55:02 +0000 2018'\n",
      "  'Despite being on opposite coasts, Dr. @AmySnover and CRMC\\'s Grover Fugate sound same on climate change: we need to change way we think about \"normal,\" and prepare for realities of climate change. And we have tools that tell us what future holds. @MetcalfURI']\n",
      " ['-82.681852' '35.421216' 'Asheville, NC' 'Thu Jun 14 19:53:37 +0000 2018'\n",
      "  '@1979MELTDOWN Why are they so relentless?\\nLike stubborn.\\ndigging-heals-in 4 nuclear?Blind to Green Energy prospects for economy &amp; turning away from Radioactive waste &amp; Climate Change.\\nWhat is up with that?\\nI am completely boggled by what is going on in their heads.']\n",
      " ['-122.191291' '37.406339' 'Stanford, CA' 'Thu Jun 14 19:48:07 +0000 2018'\n",
      "  \"@elonmusk Going to the ends of the earth to relay this concept. Left your birthday present at Tesla HQ.\\n\\nDon't open it yet. You still got two weeks to wait on this climate change thing. ;) https://t.co/nF8ty7wv3A\"]\n",
      " ['-123.224215' '49.19854' 'Vancouver, British Columbia'\n",
      "  'Thu Jun 14 19:31:17 +0000 2018'\n",
      "  'Whatever economic benefits are promised to arrive from a nationalized #TransMountain pipeline and tanker expansion, it will be dwarfed by the massive economic damage from #climate change. https://t.co/J3EHrm6I1U #bcpoili #ableg #cdnpoi']\n",
      " ['-1.2652424' '54.510978' 'Stainton, England'\n",
      "  'Thu Jun 14 19:26:32 +0000 2018'\n",
      "  '@BBCSpringwatch @OurBluePlanet Springwatch is guilty as anyone by ignoring the very real plastic problem in the ocean. Instead you have hammered on about climate change for years ignoring tangible ecological issues. You are late joining the party #plasticpollution']]\n"
     ]
    }
   ],
   "source": [
    "print (sample[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(sample, columns=['long','lat','self_reported_location','date','text'])\n",
    "sample_df.to_csv('../wyns/data/sample.csv', encoding='utf-8', index=False)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sample.csv') as f: \n",
    "    for line in f:\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_tweet_data(tweet):\n",
    "    data = []\n",
    "    if tweet['geo'] is not None:  # Checks to see if any coord data was saved in geo\n",
    "        data.append([tweet['geo']['coordinates'][0],\n",
    "                     tweet['geo']['coordinates'][1],\n",
    "                     tweet['place']['full_name'],\n",
    "                     tweet['created_at'], \n",
    "                     tweet['text']])\n",
    "    elif tweet['place'] is not None: # Checks to see if any coord data saved in place \n",
    "        data.append([tweet['place']['bounding_box']['coordinates'][0][0][0],\n",
    "                     tweet['place']['bounding_box']['coordinates'][0][0][1],\n",
    "                     tweet['place']['full_name'],\n",
    "                     tweet['created_at'],\n",
    "                     tweet['text']])\n",
    "    else:\n",
    "        pass \n",
    "    sample = np.array(data)\n",
    "    sample_df = pd.DataFrame(sample, columns=['long','lat','self_reported_location','date','text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_exists(file_name):\n",
    "    \n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "    df.to_csv(f, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
