{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neal\\Anaconda3\\envs\\keras\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\neal\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import json\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Input, Bidirectional, LSTM, regularizers\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change these to match your file paths :)\n",
    "filename = '../wyns/data/tweet_global_warming.csv' #64,706 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word_vector_model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(txt, vocab=None, replace_char=' ',\n",
    "                max_length=300, pad_out=False,\n",
    "                to_lower=True, reverse = False,\n",
    "                truncate_left=False, encoding=None,\n",
    "                letters_only=False):\n",
    "  \n",
    "    txt = txt.split()\n",
    "    # Remove HTML\n",
    "    # This will keep characters and other symbols\n",
    "    txt = [re.sub(r'http:.*', '', r) for r in txt]\n",
    "    txt = [re.sub(r'https:.*', '', r) for r in txt]\n",
    "    \n",
    "    txt = ( \" \".join(txt))\n",
    "    # Remove non-emoticon punctuation and numbers\n",
    "    txt = re.sub(\"[.,!0-9]\", \" \", txt)\n",
    "    if letters_only: \n",
    "        txt = re.sub(\"[^a-zA-Z]\", \" \", txt)\n",
    "    txt = \" \".join(txt.split())\n",
    "    # store length for multiple comparisons\n",
    "    txt_len = len(txt)\n",
    "\n",
    "    if truncate_left:\n",
    "        txt = txt[-max_length:]\n",
    "    else:\n",
    "        txt = txt[:max_length]\n",
    "    # change case\n",
    "    if to_lower:\n",
    "        txt = txt.lower()\n",
    "    # Reverse order\n",
    "    if reverse:\n",
    "        txt = txt[::-1]\n",
    "    # replace chars\n",
    "    if vocab is not None:\n",
    "        txt = ''.join([c if c in vocab else replace_char for c in txt])\n",
    "    # re-encode text\n",
    "    if encoding is not None:\n",
    "        txt = txt.encode(encoding, errors=\"ignore\")\n",
    "    # pad out if needed\n",
    "    if pad_out and max_length>txt_len:\n",
    "        txt = txt + replace_char * (max_length - txt_len)\n",
    "    if txt.find('@') > -1:\n",
    "        print(len(txt.split('@'))-1)\n",
    "        print(txt.split('@'))\n",
    "        for i in range(len(txt.split('@'))-1):\n",
    "            try:\n",
    "                if str(txt.split('@')[1]).find(' ') > -1:\n",
    "                    to_remove = '@' + str(txt.split('@')[1].split(' ')[0]) + \" \"\n",
    "                else:\n",
    "                    to_remove = '@' + str(txt.split('@')[1])\n",
    "                print(to_remove)\n",
    "                txt = txt.replace(to_remove,'')\n",
    "            except:\n",
    "                pass\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['this is a sentence ', 'sarahisabutthead with ', 'sarah things :) and a link ', 'blah']\n",
      "@sarahisabutthead \n",
      "@sarah \n",
      "@blah\n",
      "this is a sentence with things :) and a link \n"
     ]
    }
   ],
   "source": [
    "# What does this normalization function look like?\n",
    "clean_text = normalize(\"This is A sentence. @sarahisabutthead with @sarah things! 123 :) and a link https://gitub.com @blah\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@dez_blanchfield @SpEducatorCWSN @VolcanoScouting @USGSVolcanoes @Volcanoes_NPS @TmanSpeaks @DioFavatas @helene_wpli @ScheuerJo @martinfredras @HelenClarkNZ @dez_blanchfield, can you explain your answer? If oceans are rising, and getting heavier, why won�t this increased weight have consequences? See: https://t.co/DupaCkMnIE\n",
      "12\n",
      "['', 'dez_blanchfield ', 'speducatorcwsn ', 'volcanoscouting ', 'usgsvolcanoes ', 'volcanoes_nps ', 'tmanspeaks ', 'diofavatas ', 'helene_wpli ', 'scheuerjo ', 'martinfredras ', 'helenclarknz ', 'dez_blanchfield can you explain your answer? if oceans are rising and getting heavier why won�t this increased weight have consequences? see:']\n",
      "@dez_blanchfield \n",
      "@speducatorcwsn \n",
      "@volcanoscouting \n",
      "@usgsvolcanoes \n",
      "@volcanoes_nps \n",
      "@tmanspeaks \n",
      "@diofavatas \n",
      "@helene_wpli \n",
      "@scheuerjo \n",
      "@martinfredras \n",
      "@helenclarknz \n",
      "can you explain your answer? if oceans are rising and getting heavier why won�t this increased weight have consequences? see:\n"
     ]
    }
   ],
   "source": [
    "string = '@dez_blanchfield @SpEducatorCWSN @VolcanoScouting @USGSVolcanoes @Volcanoes_NPS @TmanSpeaks @DioFavatas @helene_wpli @ScheuerJo @martinfredras @HelenClarkNZ @dez_blanchfield, can you explain your answer? If oceans are rising, and getting heavier, why won�t this increased weight have consequences? See: https://t.co/DupaCkMnIE'\n",
    "print(string)\n",
    "print(normalize(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to balance the distrubtion of sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balance(df):\n",
    "    print(\"Balancing the classes\")\n",
    "    type_counts = df['Sentiment'].value_counts()\n",
    "    min_count = min(type_counts.values)\n",
    "\n",
    "    balanced_df = None\n",
    "    for key in type_counts.keys():\n",
    "\n",
    "        df_sub = df[df['Sentiment']==key].sample(n=min_count, replace=False)\n",
    "        if balanced_df is not None:\n",
    "            balanced_df = balanced_df.append(df_sub)\n",
    "        else:\n",
    "            balanced_df = df_sub\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_sentiment(review):\n",
    "    # Review is coming in as Y/N/NaN\n",
    "    # this then cleans the summary and review and gives it a positive or negative value\n",
    "    norm_text = normalize(review[0])\n",
    "    if review[1] in ('Yes', 'Y'):\n",
    "        return ['positive', norm_text]\n",
    "    elif review[1] in ('No', 'N'):\n",
    "        return ['negative', norm_text]\n",
    "    else:\n",
    "        return ['other', norm_text]\n",
    "    \n",
    "data = []\n",
    "with open(filename, 'r', encoding='latin') as f: \n",
    "    for i,line in enumerate(f):\n",
    "        if i == 0: #skip header while i diagnose\n",
    "            continue\n",
    "        # as we read in, clean\n",
    "        line_data = line.split(\",\")\n",
    "        data.append(review_to_sentiment(line_data))\n",
    "        \n",
    "twitter = pd.DataFrame(data, columns=['Sentiment', 'clean_text'], dtype=str)\n",
    "# print(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo lets just keep one and five stars the others are marked 'other\n",
    "# twitter = twitter[twitter['Sentiment'].isin(['positive', 'negative'])]\n",
    "# twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing the classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanced_twitter = balance(twitter)\n",
    "# len(balanced_twitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now go from the pandas into lists of text and labels\n",
    "\n",
    "text = twitter['clean_text'].values\n",
    "labels_0 = pd.get_dummies(twitter['Sentiment'])  # mapping of the labels with dummies (has headers)\n",
    "labels = labels_0.values # removes the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:10] # negative, other, positive\n",
    "labels = labels[:,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10] # negative, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the Train/test split\n",
    "X_train_, X_test_, Y_train_, Y_test_ = train_test_split(text,labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "max_len = 40\n",
    "batch_size = 32\n",
    "embed_dim = 300\n",
    "lstm_out = 140\n",
    "\n",
    "dense_out=len(labels[0])\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(X_train_)\n",
    "X_train = tokenizer.texts_to_sequences(X_train_)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test_)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "gb = GradientBoostingClassifier(n_estimators = 4000)\n",
    "gb = MultiOutputClassifier(gb, n_jobs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6691297208538588\n"
     ]
    }
   ],
   "source": [
    "gb.fit(X_train,Y_train_)\n",
    "print(gb.score(X_test,Y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look \n",
      " at \n",
      " me \n",
      " go\n"
     ]
    }
   ],
   "source": [
    "blah = 'look \\n at \\n me \\n go'\n",
    "blah2 = blah.replace\n",
    "print(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the data look like?\n",
    "# It is a one-hot encoding of the label, either positive or negative\n",
    "Y_train_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"d c snowstorm: how global warming makes blizzards worse: there\\'s scarcely any powder in vancouver'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Now for a simple bidirectional LSTM algorithm we set our feature sizes and train a tokenizer\n",
    "# First we Tokenize and get the data into a form that the model can read - this is BoW\n",
    "# In this cell we are also going to define some of our hyperparameters\n",
    "\n",
    "max_fatures = 2000\n",
    "max_len = 40\n",
    "batch_size = 32\n",
    "embed_dim = 300\n",
    "lstm_out = 140\n",
    "\n",
    "dense_out=len(labels[0]) #length of features\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(X_train_)\n",
    "X_train = tokenizer.texts_to_sequences(X_train_)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test_)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1191,  213,  187,    3,    4,  450,  118,   61,   17, 1191,   49,\n",
       "       1325,   13,    5,   14,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now what does our data look like?\n",
    "# Tokenizer creates a BOW encoding, which is then going to be fed into our Embedding matrix\n",
    "# This will be used by the model to build up a word embedding\n",
    "X_test[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n",
       "       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n",
       "       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n",
       "        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938,\n",
       "        0.375     ,  0.171875  ,  0.21386719, -0.19921875,  0.13085938,\n",
       "       -0.07275391, -0.02819824,  0.11621094,  0.15332031,  0.09082031,\n",
       "        0.06787109, -0.0300293 , -0.16894531, -0.20800781, -0.03710938,\n",
       "       -0.22753906,  0.26367188,  0.012146  ,  0.18359375,  0.31054688,\n",
       "       -0.10791016, -0.19140625,  0.21582031,  0.13183594, -0.03515625,\n",
       "        0.18554688, -0.30859375,  0.04785156, -0.10986328,  0.14355469,\n",
       "       -0.43554688, -0.0378418 ,  0.10839844,  0.140625  , -0.10595703,\n",
       "        0.26171875, -0.17089844,  0.39453125,  0.12597656, -0.27734375,\n",
       "       -0.28125   ,  0.14746094, -0.20996094,  0.02355957,  0.18457031,\n",
       "        0.00445557, -0.27929688, -0.03637695, -0.29296875,  0.19628906,\n",
       "        0.20703125,  0.2890625 , -0.20507812,  0.06787109, -0.43164062,\n",
       "       -0.10986328, -0.2578125 , -0.02331543,  0.11328125,  0.23144531,\n",
       "       -0.04418945,  0.10839844, -0.2890625 , -0.09521484, -0.10351562,\n",
       "       -0.0324707 ,  0.07763672, -0.13378906,  0.22949219,  0.06298828,\n",
       "        0.08349609,  0.02929688, -0.11474609,  0.00534058, -0.12988281,\n",
       "        0.02514648,  0.08789062,  0.24511719, -0.11474609, -0.296875  ,\n",
       "       -0.59375   , -0.29492188, -0.13378906,  0.27734375, -0.04174805,\n",
       "        0.11621094,  0.28320312,  0.00241089,  0.13867188, -0.00683594,\n",
       "       -0.30078125,  0.16210938,  0.01171875, -0.13867188,  0.48828125,\n",
       "        0.02880859,  0.02416992,  0.04736328,  0.05859375, -0.23828125,\n",
       "        0.02758789,  0.05981445, -0.03857422,  0.06933594,  0.14941406,\n",
       "       -0.10888672, -0.07324219,  0.08789062,  0.27148438,  0.06591797,\n",
       "       -0.37890625, -0.26171875, -0.13183594,  0.09570312, -0.3125    ,\n",
       "        0.10205078,  0.03063965,  0.23632812,  0.00582886,  0.27734375,\n",
       "        0.20507812, -0.17871094, -0.31445312, -0.01586914,  0.13964844,\n",
       "        0.13574219,  0.0390625 , -0.29296875,  0.234375  , -0.33984375,\n",
       "       -0.11816406,  0.10644531, -0.18457031, -0.02099609,  0.02563477,\n",
       "        0.25390625,  0.07275391,  0.13574219, -0.00138092, -0.2578125 ,\n",
       "       -0.2890625 ,  0.10107422,  0.19238281, -0.04882812,  0.27929688,\n",
       "       -0.3359375 , -0.07373047,  0.01879883, -0.10986328, -0.04614258,\n",
       "        0.15722656,  0.06689453, -0.03417969,  0.16308594,  0.08642578,\n",
       "        0.44726562,  0.02026367, -0.01977539,  0.07958984,  0.17773438,\n",
       "       -0.04370117, -0.00952148,  0.16503906,  0.17285156,  0.23144531,\n",
       "       -0.04272461,  0.02355957,  0.18359375, -0.41601562, -0.01745605,\n",
       "        0.16796875,  0.04736328,  0.14257812,  0.08496094,  0.33984375,\n",
       "        0.1484375 , -0.34375   , -0.14160156, -0.06835938, -0.14648438,\n",
       "       -0.02844238,  0.07421875, -0.07666016,  0.12695312,  0.05859375,\n",
       "       -0.07568359, -0.03344727,  0.23632812, -0.16308594,  0.16503906,\n",
       "        0.1484375 , -0.2421875 , -0.3515625 , -0.30664062,  0.00491333,\n",
       "        0.17675781,  0.46289062,  0.14257812, -0.25      , -0.25976562,\n",
       "        0.04370117,  0.34960938,  0.05957031,  0.07617188, -0.02868652,\n",
       "       -0.09667969, -0.01281738,  0.05859375, -0.22949219, -0.1953125 ,\n",
       "       -0.12207031,  0.20117188, -0.42382812,  0.06005859,  0.50390625,\n",
       "        0.20898438,  0.11230469, -0.06054688,  0.33203125,  0.07421875,\n",
       "       -0.05786133,  0.11083984, -0.06494141,  0.05639648,  0.01757812,\n",
       "        0.08398438,  0.13769531,  0.2578125 ,  0.16796875, -0.16894531,\n",
       "        0.01794434,  0.16015625,  0.26171875,  0.31640625, -0.24804688,\n",
       "        0.05371094, -0.0859375 ,  0.17089844, -0.39453125, -0.00156403,\n",
       "       -0.07324219, -0.04614258, -0.16210938, -0.15722656,  0.21289062,\n",
       "       -0.15820312,  0.04394531,  0.28515625,  0.01196289, -0.26953125,\n",
       "       -0.04370117,  0.37109375,  0.04663086, -0.19726562,  0.3046875 ,\n",
       "       -0.36523438, -0.23632812,  0.08056641, -0.04248047, -0.14648438,\n",
       "       -0.06225586, -0.0534668 , -0.05664062,  0.18945312,  0.37109375,\n",
       "       -0.22070312,  0.04638672,  0.02612305, -0.11474609,  0.265625  ,\n",
       "       -0.02453613,  0.11083984, -0.02514648, -0.12060547,  0.05297852,\n",
       "        0.07128906,  0.00063705, -0.36523438, -0.13769531, -0.12890625],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a word vector look like?\n",
    "# Ahhhh, like a bunch of numbers\n",
    "word_vector_model.word_vec('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the embedding matrix\n"
     ]
    }
   ],
   "source": [
    "print('Prepare the embedding matrix')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(max_fatures, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_len:\n",
    "        continue\n",
    "    # words not found in embedding index will be all-zeros.\n",
    "    if word in word_vector_model.vocab:\n",
    "        embedding_matrix[i] = word_vector_model.word_vec(word)\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = True to fine tune the embeddings\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embed_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_fatures,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17871094,  0.32617188, -0.11865234,  0.12060547, -0.15527344,\n",
       "       -0.2109375 ,  0.00460815, -0.03881836, -0.0067749 ,  0.16796875,\n",
       "        0.02294922, -0.08203125, -0.12988281, -0.09814453, -0.02966309,\n",
       "        0.20703125, -0.22070312,  0.34765625,  0.14550781, -0.20898438,\n",
       "        0.00286865,  0.1796875 , -0.11132812, -0.04956055, -0.03588867,\n",
       "       -0.07275391, -0.0859375 , -0.07910156,  0.09277344, -0.00193787,\n",
       "       -0.01220703, -0.09228516, -0.12060547,  0.20410156, -0.0378418 ,\n",
       "       -0.06201172, -0.09130859, -0.02746582,  0.09130859,  0.06298828,\n",
       "        0.04418945, -0.11083984, -0.12597656,  0.390625  , -0.13085938,\n",
       "       -0.08154297,  0.11914062,  0.12451172, -0.46484375,  0.22949219,\n",
       "        0.0456543 ,  0.05834961, -0.30859375, -0.27148438, -0.13085938,\n",
       "       -0.07617188, -0.14160156, -0.12011719, -0.13085938, -0.05615234,\n",
       "       -0.23828125,  0.02368164, -0.13183594, -0.05395508,  0.07470703,\n",
       "       -0.07177734,  0.26171875,  0.11181641,  0.06689453,  0.03686523,\n",
       "       -0.07470703,  0.15527344,  0.25976562, -0.09619141, -0.23339844,\n",
       "       -0.1875    ,  0.09570312,  0.29882812, -0.24121094, -0.07861328,\n",
       "        0.2265625 ,  0.16601562, -0.17871094, -0.41601562,  0.00604248,\n",
       "        0.12353516, -0.04467773,  0.125     , -0.0480957 ,  0.25390625,\n",
       "        0.23730469, -0.22363281, -0.22265625,  0.0291748 , -0.07421875,\n",
       "        0.03955078,  0.16894531,  0.02966309,  0.39453125, -0.26757812,\n",
       "       -0.02355957, -0.05126953, -0.25585938,  0.17675781, -0.04003906,\n",
       "        0.04858398, -0.265625  ,  0.20703125, -0.13964844, -0.24121094,\n",
       "        0.06640625, -0.01757812, -0.13476562, -0.05688477,  0.17871094,\n",
       "       -0.1484375 ,  0.265625  , -0.05029297, -0.13671875,  0.33398438,\n",
       "       -0.21484375, -0.25976562,  0.02990723,  0.296875  , -0.06787109,\n",
       "        0.04345703,  0.00396729, -0.08300781, -0.1328125 , -0.09033203,\n",
       "        0.09570312, -0.04785156, -0.09814453, -0.04785156,  0.05200195,\n",
       "        0.21679688,  0.01397705, -0.09619141, -0.14355469, -0.10009766,\n",
       "        0.25390625, -0.19238281,  0.04467773, -0.11816406,  0.13183594,\n",
       "       -0.09765625,  0.22558594, -0.00811768,  0.27148438,  0.03857422,\n",
       "        0.10888672, -0.20410156,  0.03344727,  0.08544922,  0.02075195,\n",
       "       -0.20214844,  0.14257812,  0.04345703, -0.01141357, -0.05493164,\n",
       "       -0.21679688, -0.07128906,  0.11035156,  0.10986328, -0.01196289,\n",
       "        0.18554688, -0.05688477, -0.04785156,  0.10595703,  0.13574219,\n",
       "       -0.09716797,  0.29882812,  0.15136719, -0.10791016, -0.04321289,\n",
       "        0.17285156, -0.28515625,  0.00787354, -0.19433594,  0.07128906,\n",
       "       -0.1953125 , -0.07666016,  0.26757812,  0.06079102, -0.03564453,\n",
       "       -0.19238281, -0.18945312,  0.31835938,  0.01531982,  0.14453125,\n",
       "       -0.14550781,  0.05029297,  0.00318909,  0.0859375 , -0.10009766,\n",
       "        0.17285156,  0.23046875, -0.04296875,  0.09472656, -0.08105469,\n",
       "       -0.12988281,  0.06835938, -0.13378906, -0.00680542,  0.14941406,\n",
       "        0.06982422,  0.45117188,  0.18457031, -0.18554688,  0.00704956,\n",
       "       -0.01086426,  0.13769531,  0.32617188,  0.17578125,  0.08544922,\n",
       "        0.15917969,  0.12304688,  0.07421875,  0.00891113,  0.171875  ,\n",
       "        0.0072937 , -0.07421875, -0.05004883, -0.03173828, -0.18554688,\n",
       "       -0.11865234,  0.41601562, -0.04785156,  0.0201416 ,  0.11132812,\n",
       "       -0.1953125 ,  0.14355469,  0.06445312, -0.19628906,  0.19335938,\n",
       "       -0.01696777,  0.02087402, -0.06347656,  0.29296875, -0.1875    ,\n",
       "        0.27539062,  0.19238281, -0.08056641, -0.02770996, -0.10351562,\n",
       "        0.15917969, -0.22070312, -0.03320312, -0.15136719, -0.01965332,\n",
       "       -0.27539062,  0.25390625, -0.07617188,  0.11767578,  0.10595703,\n",
       "       -0.06494141,  0.56640625,  0.10986328, -0.15429688,  0.08740234,\n",
       "       -0.00216675, -0.15527344, -0.02697754,  0.18066406,  0.22753906,\n",
       "        0.41210938, -0.375     , -0.08544922, -0.08007812, -0.37304688,\n",
       "       -0.18359375,  0.11523438, -0.03930664,  0.1015625 , -0.23144531,\n",
       "        0.06005859, -0.36328125, -0.17480469,  0.09863281,  0.04394531,\n",
       "        0.14648438, -0.16308594,  0.07714844,  0.00082397,  0.15332031,\n",
       "       -0.22851562,  0.16113281, -0.44921875,  0.03686523,  0.18945312,\n",
       "       -0.39453125,  0.15429688,  0.17382812,  0.20117188,  0.21191406,\n",
       "        0.13574219, -0.00360107,  0.41796875,  0.31445312,  0.06542969])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 2000, 300)         600000    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 280)               493920    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 562       \n",
      "=================================================================\n",
      "Total params: 1,094,482\n",
      "Trainable params: 1,094,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4872 samples, validate on 1218 samples\n",
      "Epoch 1/80\n",
      " - 23s - loss: 0.2532 - acc: 0.4511 - val_loss: 0.1835 - val_acc: 0.5690\n",
      "Epoch 2/80\n",
      " - 20s - loss: 0.1645 - acc: 0.5831 - val_loss: 0.1740 - val_acc: 0.5772\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6ea77df172ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m model_hist_embedding = model.fit(X_train, Y_train_, epochs = 80, batch_size=batch_size, verbose = 2,\n\u001b[1;32m---> 21\u001b[1;33m                     validation_data=(X_test,Y_test_))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model using the pre-trained embedding\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/cpu:0'):\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embed_dim,\n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=max_fatures,\n",
    "                        trainable=True)\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(lstm_out, recurrent_dropout=0.5, activation='tanh'))(embedded_sequences)\n",
    "# preds = Dense(250, activation='softmax')(x)\n",
    "preds = Dense(dense_out, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "print(model.summary())\n",
    "model_hist_embedding = model.fit(X_train, Y_train_, epochs = 80, batch_size=batch_size, verbose = 2,\n",
    "                    validation_data=(X_test,Y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4872 samples, validate on 1218 samples\n",
      "Epoch 1/80\n",
      " - 23s - loss: 0.0683 - acc: 0.6275 - val_loss: 0.2834 - val_acc: 0.5583\n",
      "Epoch 2/80\n",
      " - 19s - loss: 0.0285 - acc: 0.6502 - val_loss: 0.3628 - val_acc: 0.5608\n",
      "Epoch 3/80\n",
      " - 20s - loss: 0.0211 - acc: 0.6470 - val_loss: 0.3950 - val_acc: 0.5780\n",
      "Epoch 4/80\n",
      " - 20s - loss: 0.0182 - acc: 0.6505 - val_loss: 0.4379 - val_acc: 0.5591\n",
      "Epoch 5/80\n",
      " - 20s - loss: 0.0186 - acc: 0.6455 - val_loss: 0.3956 - val_acc: 0.5583\n",
      "Epoch 6/80\n",
      " - 21s - loss: 0.0179 - acc: 0.6476 - val_loss: 0.3799 - val_acc: 0.5821\n",
      "Epoch 7/80\n",
      " - 19s - loss: 0.0144 - acc: 0.6502 - val_loss: 0.4838 - val_acc: 0.5575\n",
      "Epoch 8/80\n",
      " - 19s - loss: 0.0119 - acc: 0.6416 - val_loss: 0.5299 - val_acc: 0.5304\n",
      "Epoch 9/80\n",
      " - 20s - loss: 0.0133 - acc: 0.6404 - val_loss: 0.4846 - val_acc: 0.5394\n",
      "Epoch 10/80\n",
      " - 19s - loss: 0.0149 - acc: 0.6443 - val_loss: 0.4657 - val_acc: 0.5468\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6c9a620405b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_hist_embedding = model.fit(X_train, Y_train_, epochs = 80, batch_size=batch_size, verbose = 2,\n\u001b[1;32m----> 2\u001b[1;33m                         validation_data=(X_test,Y_test_))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_hist_embedding = model.fit(X_train, Y_train_, epochs = 80, batch_size=batch_size, verbose = 2,\n",
    "                        validation_data=(X_test,Y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff37f69f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "x = np.arange(20)+1\n",
    "\n",
    "plt.plot(x, model_hist_embedding.history['acc'])\n",
    "plt.plot(x, model_hist_embedding.history['val_acc'])\n",
    "plt.legend(['Training', 'Testing'], loc='lower right')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.45,1.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"LSTM Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_hist_embedding.model.save(\"../../wyns/data/climate_sentiment_m2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
