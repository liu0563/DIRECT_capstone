{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Twitter Sentiment Analysis in Python: The Base Model\n",
    "\n",
    "This notebook will eventually be populated with:\n",
    "1. TF-IDF with log regression and regularized log regression\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. TF-IDF\n",
    "    1. [bag of shapes](#tfidf)\n",
    "    2. [twitter TF-IDF](#tfidftweet)\n",
    "2. log regression\n",
    "    1. [derivation](#log)\n",
    "    2. [string vectorization](#vectorization)\n",
    "    3. [bag of shapes](#bag)\n",
    "    4. [twitter log regression](#logtweet)\n",
    "\n",
    "You can read more about TF-IDF and simple regressions in this [paper](http://www.cs.ubc.ca/~nando/540-2013/projects/p9.pdf) and this blog [post](https://www.ocf.berkeley.edu/~janastas/supervised-learning-with-text-1-03-01-sheet.html)\n",
    "\n",
    "And, well, while we're at it I've enjoyed the documentation for [gensim](https://radimrehurek.com/gensim/models/tfidfmodel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tfidf'></a>\n",
    "\n",
    "### Term Frequency Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "[back to top](#top)\n",
    "\n",
    "The basic idea of TF-IDF is to score words in a document based on how well they discern the document from the rest of the corpus. You can think of it as selecting the unique objects in each of a set of bags that distinguishes that bag from the set:\n",
    "\n",
    "<img src=\"tfidf.png\" alt=\"Drawing\" width=\"200\"/>\n",
    "\n",
    "In this case, the highest scoring shapes for the left bag would be the red triangles, and the highest scoring shape in the right bag would be the orange chord. Let's work this out mathematically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_a = [\"triangle\", \"triangle\", \"circle\", \"circle\", \"star\"]\n",
    "bag_b = [\"chord\", \"star\", \"circle\", \"circle\", \"circle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequency (TF) and inverse document frequency (IDF) terms are computed indivudally, before being combined. Both the TF, IDF, and their combination can be computed in a variety of ways to attune for a particular corpus or desired analysis. Here I'll demonstrate the simplest case. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Term frequency**\n",
    "\n",
    "The TF can be computed as follows:\n",
    "\n",
    "$TF_{t,d} = \\frac{\\sum_{i=1}^{w_{d}}1(w_{i} = t)}{w_{d}}$\n",
    "\n",
    "where we are tabulating the frequency of word (shape), t in document (bag), d and $w_{d}$ normalizes for the number of words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def tf_shapes(shape, bag):\n",
    "    return Counter(bag)[shape] / sum(Counter(bag).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the scores for each of our shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triangle tf for bag a:\t 0.4\n",
      "circle tf for bag a:\t 0.4\n",
      "star tf for bag a:\t 0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"triangle tf for bag a:\\t {}\".format(tf_shapes(\"triangle\", bag_a)))\n",
    "print(\"circle tf for bag a:\\t {}\".format(tf_shapes(\"circle\", bag_a)))\n",
    "print(\"star tf for bag a:\\t {}\".format(tf_shapes(\"star\", bag_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that for `bag_a` circle and triangle receive the same score. In the context of the set of bags, we know that triangle should be more discerning than circle. This discrepancy is addressed by the IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverse document frequency**\n",
    "\n",
    "The IDF can be computed as follows:\n",
    "\n",
    "$IDF_{t,D} = ln\\left(\\frac{D}{1 + \\sum_{j=1}^{D}1(d_{j} = t)}\\right)$\n",
    "\n",
    "where we logarithmically scale the number of documents in the corpus over the times word, t appears in the corpus, D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log as ln\n",
    "def idf_shapes(shape, set_of_bags):\n",
    "    return ln(sum(len(bag) for bag in set_of_bags) / sum(1 for bag in set_of_bags if shape in bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the scores for each of our shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triangle idf for bag a:\t 2.3\n",
      "circle idf for bag a:\t 1.6\n",
      "star idf for bag a:\t 1.6\n"
     ]
    }
   ],
   "source": [
    "print(\"triangle idf for bag a:\\t {:.2}\".format(idf_shapes(\"triangle\", [bag_a, bag_b])))\n",
    "print(\"circle idf for bag a:\\t {:.2}\".format(idf_shapes(\"circle\", [bag_a, bag_b])))\n",
    "print(\"star idf for bag a:\\t {:.2}\".format(idf_shapes(\"star\", [bag_a, bag_b])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that triangle scores higher than circle within the set of bags (2.3 vs 1.6). Our last step is to see how this computes into a final tf-idf score.\n",
    "\n",
    "The simplest TF-IDF can be computed by multiplying the TF and IDF together:\n",
    "\n",
    "$TF * IDF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_shapes(shape, bag, set_of_bags):\n",
    "    return tf_shapes(shape, bag) * idf_shapes(shape, set_of_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the final tf-idf for each of our shapes in bag_a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triangle tf-idf for bag a:\t 0.92\n",
      "circle tf-idf for bag a:\t 0.64\n",
      "star tf-idf for bag a:\t\t 0.32\n"
     ]
    }
   ],
   "source": [
    "print(\"triangle tf-idf for bag a:\\t {:.2}\".format(tfidf_shapes(\"triangle\", bag_a, [bag_a, bag_b])))\n",
    "print(\"circle tf-idf for bag a:\\t {:.2}\".format(tfidf_shapes(\"circle\", bag_a, [bag_a, bag_b])))\n",
    "print(\"star tf-idf for bag a:\\t\\t {:.2}\".format(tfidf_shapes(\"star\", bag_a, [bag_a, bag_b])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viola! we've correctly identified triangle as the most discerning word in `bag_a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tfidftweet'></a>\n",
    "\n",
    "### TF-IDF Analysis on Twitter Feed ###\n",
    "\n",
    "[back to top](#top)\n",
    "\n",
    "The documents in our corpus are very short (280 characters)... so the term frequency calculation will really only differentiate stop words, the only words appearing multiple times in a given tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 6090\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../core/data/tweet_global_warming.csv\", encoding=\"latin\") #load the corpus\n",
    "print(\"Total tweets: {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a simplified text processing library to convert our above tfidf code into something higher-performing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb #text processing library\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I've truncated our loop so as not to print out 6090 tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in tweet 1\n",
      "\tWord: act|BRUSSELS, TF-IDF: 0.45801\n",
      "\tWord: Belgium, TF-IDF: 0.45801\n",
      "\tWord: hunger, TF-IDF: 0.45801\n",
      "Top words in tweet 2\n",
      "\tWord: poverty, TF-IDF: 0.73515\n",
      "\tWord: Fighting, TF-IDF: 0.66839\n",
      "\tWord: Africa, TF-IDF: 0.66415\n",
      "Top words in tweet 3\n",
      "\tWord: Vatican, TF-IDF: 0.51245\n",
      "\tWord: failed, TF-IDF: 0.51245\n",
      "\tWord: offsets, TF-IDF: 0.48534\n",
      "Top words in tweet 4\n",
      "\tWord: Vatican, TF-IDF: 0.51245\n",
      "\tWord: failed, TF-IDF: 0.51245\n",
      "\tWord: offsets, TF-IDF: 0.48534\n",
      "Top words in tweet 5\n",
      "\tWord: URUGUAY, TF-IDF: 0.58289\n",
      "\tWord: Tools, TF-IDF: 0.58289\n",
      "\tWord: Needed, TF-IDF: 0.58289\n",
      "Top words in tweet 6\n",
      "\tWord: JaymiHeimbuch, TF-IDF: 0.48854\n",
      "\tWord: sejorg, TF-IDF: 0.46151\n",
      "\tWord: Intensifying, TF-IDF: 0.42745\n",
      "Top words in tweet 7\n",
      "\tWord: around, TF-IDF: 0.61988\n",
      "\tWord: us|A, TF-IDF: 0.36861\n",
      "\tWord: doubters, TF-IDF: 0.33369\n",
      "Top words in tweet 8\n",
      "\tWord: Migratory, TF-IDF: 0.81423\n",
      "\tWord: Stay, TF-IDF: 0.76918\n",
      "\tWord: Strategy, TF-IDF: 0.73722\n",
      "Top words in tweet 9\n",
      "\tWord: Competing, TF-IDF: 0.48854\n",
      "\tWord: Limpopo, TF-IDF: 0.48854\n",
      "\tWord: Southe, TF-IDF: 0.48854\n",
      "Top words in tweet 10\n",
      "\tWord: wheat, TF-IDF: 0.36435\n",
      "\tWord: India|Ludhiana, TF-IDF: 0.36435\n",
      "\tWord: Scarcity, TF-IDF: 0.36435\n",
      "Top words in tweet 11\n",
      "\tWord: solve, TF-IDF: 0.65347\n",
      "\tWord: thing, TF-IDF: 0.54047\n",
      "\tWord: do, TF-IDF: 0.41153\n"
     ]
    }
   ],
   "source": [
    "bloblist = list(map(tb, data.iloc[:,0]))\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in tweet {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our TF-IDF analysis is behaving like we'd expect it to: unusual words (in the context of climate sentiment tweets) score highest. But you'll notice textblob is improperly handling some of our wordage (us|A, India|Ludhiana, etc.) Let's take advantage of another text processing library to properly preprocess our twitter feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "def read_data(data_file):\n",
    "    for i, line in enumerate (data_file): \n",
    "        yield gensim.utils.simple_preprocess (line)\n",
    "        \n",
    "dataset = list(read_data(data['tweet']))\n",
    "dct = Dictionary(dataset)\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n",
    "model = TfidfModel(corpus)\n",
    "vector = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we're interested, we can now checkout the scores for each word in every tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270\tglobal\n",
      "0.090\twarming\n",
      "0.243\treport\n",
      "0.372\turges\n",
      "0.372\tgovernments\n",
      "0.297\tto\n",
      "0.034\tact\n",
      "0.318\tbrussels\n",
      "0.347\tbelgium\n",
      "0.287\tap\n",
      "0.089\tthe\n",
      "0.174\tworld\n",
      "0.055\tfaces\n",
      "0.062\tincreased\n",
      "0.331\thunger\n",
      "0.035\tand\n",
      "0.172\tlink\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vector)):\n",
    "    print(\"{!s:.5}\\t{}\".format(vector[i][1], dataset[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words like 'and' and 'the' score extremely low while words appearing far less in the twitter corpus like 'hunger' and 'governments' score much higher. As we would expect in this corpus filtered for climate sentiment, 'warming' receives a very low score - on par with the stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log'></a>\n",
    "\n",
    "### Log Regression\n",
    "\n",
    "[back to top](#top)\n",
    "\n",
    "We've reviewed TF-IDF and its implementation on our twitter data. Eventually, we will use it in a preprocessing step when creating a classification model. Before that, let's review the simplest classification model, logistic regression.\n",
    "\n",
    "logistic regression is where the log odds of the propability of an outcome are represented by a linear combination of features (independent variables). \n",
    "\n",
    "The logistic function is defined as:\n",
    "\n",
    "$\\sigma(h) = \\frac{\\exp^h}{\\exp^h+1} $\n",
    "\n",
    "where $h$ (also called the hypothesis in machine learning parlance) is a linear combination of features:\n",
    "\n",
    "$h_{\\theta}(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_mx_m$\n",
    "\n",
    "The inverse of the logistic funtion is sometimes called logit, hence the name logistic.\n",
    "\n",
    "In a linear regression, we would minimize the least-squares function (the error between real output values and predicted output values) to determine the coefficients for the model:\n",
    "\n",
    "$J(\\theta)=\\frac{1}{2}\\sum\\limits_{i=1}^{m} (h_\\theta(x^i)-y^i)^2 \\to min$\n",
    "\n",
    "Unfortunately, there is no closed-form solution for minimizing the logistic cost function (or maximizing the inverse, the log-likelihood) aside from some very special [cases](https://www.tandfonline.com/doi/abs/10.1080/02664763.2014.932760).\n",
    "\n",
    "To circumvent this, we use an optimization algorithm called gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent ####\n",
    "\n",
    "Adapting the least-squares function above to reflect our ouput mapping from 0 to 1, the cost function in logistic regression is:\n",
    "\n",
    "$J(\\theta)=\\frac{1}{m}\\sum\\limits_{i=1}^{m} (-y^i\\ln(h_\\theta(x^i))-(1-y^i)\\ln(1-h_\\theta(x^i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, Y, theta, lambda_=0): \n",
    "    J = 0 #cost initialization\n",
    "    H = sigmoid(np.dot(X, theta)) #the hypothesis\n",
    "    J = 1/(m) * np.sum(-Y[i]*np.log(H[i])-(1-Y[i])*np.log(1-H[i]) for i in range (m))   \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the hypothesis $h_\\theta$:\n",
    "\n",
    "$h_\\theta(x)=\\sigma(\\theta^Tx)= \\frac{1}{1 + \\exp^{-\\theta^Tx}}$\n",
    "\n",
    "includes the logistic function that ranges our hypothesis from 0 to 1:\n",
    "\n",
    "$\\sigma(z)=\\frac{1}{1+e^-z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):    \n",
    "    g = 1/(1+np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, this is known as the sigmoid function, a special case of the logistic function (and there are other smooth functions we could have chosen). \n",
    "\n",
    "Finally, we need to pull these functions together and form a gradient (the partial derivatives of the cost function with respect to each value of theta) so that we can optimize our values for theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y, theta, lambda_=0):    \n",
    "    grad = np.zeros(theta.shape)\n",
    "    H = sigmoid(np.dot(X, theta))   \n",
    "    grad = (1/m)*(H - np.mat(Y))*X\n",
    "    return np.ravel(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthogonality in Numerical Text Representation\n",
    "\n",
    "In order to continue our bag of shapes example, we'll have to create some data. It is here that we are forced to make a decision about how to represent our string data numerically. In the simplest case, we could imagine that we represent every unique string by a unique number:\n",
    "\n",
    "* triangle = 1\n",
    "* circle = 2\n",
    "* star = 3\n",
    "\n",
    "But now we have these weird unwanted relationships between our features:\n",
    "\n",
    "* star = circle + triangle\n",
    "* circle = (triangle + star) /2\n",
    "* etc...\n",
    "\n",
    "To circumvent this, we can represent our strings with vectors. The particular vectorization I'm going to use is one hot encoding. The resultant vectors are orthogonal (they can't be used to operate on each other) because they are zero everywhere aside from one elemental position that is unqiue to that vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle = [0, 0, 0, 1] # one hot encode shapes\n",
    "circle = [0, 0, 1, 0]\n",
    "star = [0, 1, 0, 0]\n",
    "chord = [1, 0, 0, 0]\n",
    "bag_type_a = [triangle, triangle, circle, circle, star]\n",
    "bag_type_b = [chord, star, circle, circle, circle]\n",
    "shapes = [triangle, circle, star, chord]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we have to flatten our vectors in order to perform logistic regression. Since I have four unique shapes and five shapes in a bag this results in a feature vector of length 20 for every bag in my dataset. I'm going to initiate a sample size of 100 bags. In this simple demonstration, I won't use a test set or introduce noise (irreducible error) in my sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros(((100,20))) # initialize X\n",
    "y = np.random.randint(0,2,size=100)\n",
    "for index, value in enumerate(y): #fill X based on Y\n",
    "    if value == 0:\n",
    "        np.random.shuffle(bag_type_a) #shuffle bag contents\n",
    "        X[index] = np.ndarray.flatten(np.array(bag_type_a))\n",
    "    else: \n",
    "        np.random.shuffle(bag_type_b) #shuffle bag contents\n",
    "        X[index] = np.ndarray.flatten(np.array(bag_type_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can look at what each of my functions are outputing before we go ahead and pass the gradient and cost function to a solver. You'll notice that in the following cell, I manually enter the y-intercept in our theta vector (it is one element longer than our feature vector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "X = np.insert(X, 0, np.ones(len(X)), 1)\n",
    "theta = np.zeros(n + 1) #insert y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is computing the error between our prediction from the current parameters in the logistic regression and the true y-labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.693147180559946"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X, y, np.array(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient computes the first derivative of the cost function with respect to each value of theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01 , -0.01 , -0.01 , -0.07 ,  0.02 , -0.025,  0.065, -0.045,\n",
       "       -0.005, -0.045,  0.085, -0.05 ,  0.02 , -0.1  ,  0.12 , -0.05 ,\n",
       "       -0.02 , -0.07 ,  0.13 , -0.04 , -0.025, -0.035,  0.09 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(X, y, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization Using Fminunc\n",
    "\n",
    "Alright we've almost arrived. We need to choose a solver to minimize our cost function. I'm going to use a built-in scipy function [fminunc](#https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.fmin_ncg.html) to optimize our values for theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CG iterations didn't converge.  The Hessian is not positive definite.\n",
      "         Current function value: 0.000138\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 1067\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "def mycost(t):\n",
    "    return cost(X, y, t)\n",
    "\n",
    "def mygrad(t):\n",
    "    return gradient(X, y, t)\n",
    "\n",
    "m, n = X.shape\n",
    "X = np.insert(X, 0, np.ones(len(X)), 1)\n",
    "theta = np.zeros(n + 1)\n",
    "optimal_theta = scipy.optimize.fmin_ncg(mycost, theta, fprime=mygrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check if our function is able to predict if a bag is a-type or b-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    T = np.insert(x, 0, 1)\n",
    "    H = sigmoid(np.dot(T, optimal_theta))       \n",
    "    if H >= 0.5:\n",
    "        p = 'bag_b'\n",
    "    else:\n",
    "        p = 'bag_a'    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no matter how we shake our bag contents, our model gets it right everytime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bag_b'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(bag_type_b)\n",
    "predict(np.ndarray.flatten(np.array(bag_type_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know preemptively that we could categorize our bags with a subset of the information (e.g. we know bag_a has two circles whereas bag_b has three, bag_b has no triangles, bag_a has no chords, etc.). Can we use our TF-IDF to preprocess our bag data to reflect this generality? Of course we can. We can imagine the most aggressive approach and retain only the highest TF-IDF shape for that bag or corpus. We could progressively decrease this aggression by retaining more and more top TF-IDF shapes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression on Twitter Data\n",
    "\n",
    "Let's now perform this analysis on our twitter data. \n",
    "\n",
    "Recall that our simple sandbox problem of four shapes in a bag of five shapes resulted in feature vectors of length 20. In the case of our twitter data, we have thousands of unique words and 280 character length \"bag\" sizes. The resultant vectors we would create with our prior method would be enormous and sparse. Common methods to circumvent this problem are to:\n",
    "\n",
    "* preprocess text with stemming (word reduction)\n",
    "* remove stop words (word reduction)\n",
    "* retain only top occuring words (word reduction)\n",
    "* vectorize words into meaningful vector space (sparsity reduction)\n",
    "\n",
    "...and there are new methods being explored all the time. Removal of stop words is a no-brainer, and we will do that here. Stemming is a harder call. Imagine the case where we now condense \"warm\", \"warmed\", and \"warming\" into a single vector representation. These words could encode vastly different sentiment in the case of whether a tweeter believe \"warming\" is occuring or the planet has \"warmed\" in the past, etc.\n",
    "\n",
    "Retaining only top occuring words is a straight-forward method of reducing our word space. We may intuit, however, that the discerning words in our corpus are what we're really after for inclusion in our model. We can use our TF-IDF analysis to do that. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### First Pass on the Twitter Feed\n",
    "##### Where we introduce keras, tokenizer, and logistic regression with sklearn\n",
    "\n",
    "Before we apply all these preprocessing steps, let's see what we get in our first pass. We'll integer-represent all the words in our dataset and include 30 words per tweet, padding the short tweets with zeros and truncating the long tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 6090\n",
      "Number of unique words: 3889\n",
      "(array(['No', 'Yes'], dtype=object), array([1114, 3111]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "data = pd.read_csv(\"../../core/data/tweet_global_warming.csv\", encoding=\"latin\")\n",
    "print(\"Full dataset: {}\".format(data.shape[0]))\n",
    "data['existence'].replace(('Y', 'N'), ('Yes', 'No'), inplace=True) \n",
    "data.dropna(inplace=True) #remove ambiguous tweets\n",
    "tweets = data.iloc[:,0]\n",
    "sentiment = data.iloc[:,1]\n",
    "print(\"Number of unique words: {}\".format(len(np.unique(np.hstack(tweets)))))\n",
    "\n",
    "top_words = 20000\n",
    "max_words = 30 #max/min vector length\n",
    "test_split = 0.25\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tweets)\n",
    "X = token.texts_to_sequences(texts=tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(np.unique(sentiment,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the logistic regression model from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.737\n",
      "testing score: 0.724\n",
      "(array(['No', 'Yes'], dtype=object), array([  50, 1007]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is biased toward 'Yes'; this baseline model is not performing super well. Our algorithm is running into the issues that motivated us to use vector representations in the bag of shapes example: there are unwarranted mathematical relationships between words and there is no protection against the shuffling of words (i.e. the same $\\theta_1$ value operates on any word appearing first within the tweet regardless of what word it is).\n",
    "\n",
    "#### Word Vectorization and Selection with TF-IDF\n",
    "\n",
    "Let's revisit our work with TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(read_data(data['tweet']))\n",
    "dct = Dictionary(dataset)\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n",
    "model = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after initiating our corpus, we're going to loop through our tweets and remove those not in the top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5\n",
    "lst = [[] for _ in range(len(dataset))]\n",
    "X = [[] for _ in range(len(dataset))]\n",
    "for j in range(len(dataset)):\n",
    "    vector = model[corpus[j]] #create tfidf vector for tweet\n",
    "    sorted_words = sorted(vector, key=lambda x: x[1], reverse=True) #sort\n",
    "    for i in range(len(vector)):\n",
    "        if vector[i][1] in [elem for sublist in sorted_words[:top_words] for elem in sublist]:\n",
    "            lst[j].append(dataset[j][i])\n",
    "            X[j].append(vector[i][0])\n",
    "tokenized_tweets = lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only keep the top 5 words for every tweet in the corpus, we're left with 4704 words! To represent these orthogonally we would have 4704-length vectors - that's extremely sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list = [item for sublist in lst for item in sublist]\n",
    "len(np.unique(np.array(flat_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many unique words, the best way to represent them would probably be with google's [word2vec](https://code.google.com/archive/p/word2vec/) model. That implementation is probably worth a post/notebook of its own. To tie this work up, let's continue to represent our words with integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.742\n",
      "testing score: 0.719\n",
      "(array(['Yes'], dtype=object), array([1057]))\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.25\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, sentiment, test_size=test_split)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=top_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=top_words)\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.00001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after distilling our tweets down to the top 5 tf-idf words for every tweet, or logistic regression breaks: we've lost enough detail to where we can only predict the median ('yes') of our corpus. \n",
    "\n",
    "Let's sum this up by reverting back to the original dataset and see how we do limiting our preprocessing to the removal of stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = stopwords.words('english') + list(string.punctuation)\n",
    "tokenized_tweets = []\n",
    "for index, tweet in enumerate(tweets):\n",
    "    tokens = [i for i in word_tokenize(tweet.lower()) if i not in stop]\n",
    "    tokenized_tweets.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.734\n",
      "testing score: 0.741\n",
      "(array(['No', 'Yes'], dtype=object), array([  38, 2075]))\n"
     ]
    }
   ],
   "source": [
    "top_words = 20000\n",
    "max_words = 30\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tokenized_tweets)\n",
    "X = token.texts_to_sequences(texts=tokenized_tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.1, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we get a small boost in our testing score, our regression is heavily relying on its ability to predict the median (only 38/2075 'no' predictions). We can also try stemming our words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Tokenize and stem\n",
    "tkr = RegexpTokenizer('[a-zA-Z0-9@]+')\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "tokenized_corpus = []\n",
    "\n",
    "for i, tweet in enumerate(tweets):\n",
    "    tokens = [stemmer.stem(t) for t in tkr.tokenize(tweet) if not t.startswith('@')]\n",
    "    tokenized_corpus.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results in a regression with more 'no' labeling. But at the expense of accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.721\n",
      "testing score: 0.709\n",
      "(array(['No', 'Yes'], dtype=object), array([ 132, 1981]))\n"
     ]
    }
   ],
   "source": [
    "top_words = 20000\n",
    "max_words = 30\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tokenized_tweets)\n",
    "X = token.texts_to_sequences(texts=tokenized_tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we've pretty much exhausted what we can get with integer-representation of our words. Next up: applying google's word2vec 300-length vector representation with logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
