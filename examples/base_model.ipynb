{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Twitter Sentiment Analysis in Python: The Base Model\n",
    "\n",
    "This notebook will eventually be populated with:\n",
    "1. Theory/explanation of TF-IDF and log regression, log odds, etc. \n",
    "2. Word vectorization\n",
    "3. Comparison of TF-IDF top scoring words and words from regularized models, i.e. LASSO\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [TF-IDF](#tfidf)\n",
    "2. [log regression](#log)\n",
    "\n",
    "Basemodel: Log Regression and TF-IDF\n",
    "\n",
    "You can read more about TF-IDF and simple regressions in this [paper](http://www.cs.ubc.ca/~nando/540-2013/projects/p9.pdf) and this dapper blog [post](https://www.ocf.berkeley.edu/~janastas/supervised-learning-with-text-1-03-01-sheet.html)\n",
    "\n",
    "And, well, while we're at it I've enjoyed the documentation for [gensim](https://radimrehurek.com/gensim/models/tfidfmodel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tfidf'></a>\n",
    "\n",
    "### TF-IDF\n",
    "\n",
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 6090\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../../core/data/tweet_global_warming.csv\", encoding=\"latin\") #load the corpus\n",
    "print(\"Total tweets: {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['global', 'warming', 'report', 'urges', 'governments', 'to', 'act', 'brussels', 'belgium', 'ap', 'the', 'world', 'faces', 'increased', 'hunger', 'and', 'link']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "def read_data(data_file):\n",
    "    for i, line in enumerate (data_file): \n",
    "        yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "dataset = list(read_data(data['tweet']))\n",
    "print (dataset[0]) #list of lists - usually bad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in tweet 1\n",
      "\tWord: act|BRUSSELS, TF-IDF: 0.45801\n",
      "\tWord: Belgium, TF-IDF: 0.45801\n",
      "\tWord: hunger, TF-IDF: 0.45801\n",
      "Top words in tweet 2\n",
      "\tWord: poverty, TF-IDF: 0.73515\n",
      "\tWord: Fighting, TF-IDF: 0.66839\n",
      "\tWord: Africa, TF-IDF: 0.66415\n",
      "Top words in tweet 3\n",
      "\tWord: Vatican, TF-IDF: 0.51245\n",
      "\tWord: failed, TF-IDF: 0.51245\n",
      "\tWord: offsets, TF-IDF: 0.48534\n",
      "Top words in tweet 4\n",
      "\tWord: Vatican, TF-IDF: 0.51245\n",
      "\tWord: failed, TF-IDF: 0.51245\n",
      "\tWord: offsets, TF-IDF: 0.48534\n",
      "Top words in tweet 5\n",
      "\tWord: URUGUAY, TF-IDF: 0.58289\n",
      "\tWord: Tools, TF-IDF: 0.58289\n",
      "\tWord: Needed, TF-IDF: 0.58289\n",
      "Top words in tweet 6\n",
      "\tWord: JaymiHeimbuch, TF-IDF: 0.48854\n",
      "\tWord: sejorg, TF-IDF: 0.46151\n",
      "\tWord: Intensifying, TF-IDF: 0.42745\n",
      "Top words in tweet 7\n",
      "\tWord: around, TF-IDF: 0.61988\n",
      "\tWord: us|A, TF-IDF: 0.36861\n",
      "\tWord: doubters, TF-IDF: 0.33369\n",
      "Top words in tweet 8\n",
      "\tWord: Migratory, TF-IDF: 0.81423\n",
      "\tWord: Stay, TF-IDF: 0.76918\n",
      "\tWord: Strategy, TF-IDF: 0.73722\n",
      "Top words in tweet 9\n",
      "\tWord: Competing, TF-IDF: 0.48854\n",
      "\tWord: Limpopo, TF-IDF: 0.48854\n",
      "\tWord: Southe, TF-IDF: 0.48854\n",
      "Top words in tweet 10\n",
      "\tWord: wheat, TF-IDF: 0.36435\n",
      "\tWord: India|Ludhiana, TF-IDF: 0.36435\n",
      "\tWord: Scarcity, TF-IDF: 0.36435\n",
      "Top words in tweet 11\n",
      "\tWord: solve, TF-IDF: 0.65347\n",
      "\tWord: thing, TF-IDF: 0.54047\n",
      "\tWord: do, TF-IDF: 0.41153\n"
     ]
    }
   ],
   "source": [
    "bloblist = list(map(tb, data.iloc[:,0]))\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in tweet {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:3]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dct = Dictionary(dataset)\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n",
    "model = TfidfModel(corpus)\n",
    "vector = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270\tglobal\n",
      "0.090\twarming\n",
      "0.243\treport\n",
      "0.372\turges\n",
      "0.372\tgovernments\n",
      "0.297\tto\n",
      "0.034\tact\n",
      "0.318\tbrussels\n",
      "0.347\tbelgium\n",
      "0.287\tap\n",
      "0.089\tthe\n",
      "0.174\tworld\n",
      "0.055\tfaces\n",
      "0.062\tincreased\n",
      "0.331\thunger\n",
      "0.035\tand\n",
      "0.172\tlink\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vector)):\n",
    "    print(\"{!s:.5}\\t{}\".format(vector[i][1], dataset[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log'></a>\n",
    "\n",
    "TF-IDF labeling may come in handy when choosing words to represent our feature space... Let's build a log regression!\n",
    "\n",
    "### Log Regression\n",
    "\n",
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wesleybeckner/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 6090\n",
      "Number of unique words: 5541\n",
      "(array(['No', 'Yes', 'ambiguous'], dtype=object), array([1114, 3111, 1865]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "data = pd.read_csv(\"../../core/data/tweet_global_warming.csv\", encoding=\"latin\")\n",
    "print(\"Full dataset: {}\".format(data.shape[0]))\n",
    "data['existence'].fillna(value='ambiguous', inplace = True) #replace NA's \n",
    "data['existence'].replace(('Y', 'N'), ('Yes', 'No'), inplace=True) \n",
    "#data.dropna(inplace=True)\n",
    "tweets = data.iloc[:,0]\n",
    "sentiment = data.iloc[:,1]\n",
    "print(\"Number of unique words: {}\".format(len(np.unique(np.hstack(tweets)))))\n",
    "\n",
    "top_words = 20000\n",
    "max_words = 30\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tweets)\n",
    "X = token.texts_to_sequences(texts=tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(np.unique(sentiment,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.511\n",
      "testing score: 0.502\n",
      "(array(['No', 'Yes', 'ambiguous'], dtype=object), array([  76, 2864,  105]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is biased toward 'Yes'. This baseline model is not performing super well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     4,     5,    51,   121,    32,  3963,\n",
       "         1669,   351,   105,    89,  1483,    38,    59,  3964,     1,\n",
       "            8,     7,  6137],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,    98,     6,  4408,   265,   375,     6,  4409,    12,\n",
       "           11,     2,    39,   273,     6,   603,  4410,   100,     4,\n",
       "            5,  4411,    17],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,    12,    59,\n",
       "         5850,    69,   102,   102,   151, 11098,   132,   356,     2,\n",
       "            3,    14, 11099,    52,  5593,    15,  3063,  5592,     1,\n",
       "            8,     7, 11100]], dtype=int32)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climate\n",
      "the\n",
      "link\n"
     ]
    }
   ],
   "source": [
    "d = token.word_index\n",
    "for name, age in d.items():    # for name, age in list.items():  (for Python 3.x)\n",
    "    if age == 6 or age == 2 or age == 17:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we'll inspect the coefficients on these words in the log regression, that will tell us if they indicate sentiment one way or the other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 3898),\n",
       " ('climate', 3447),\n",
       " ('change', 3279),\n",
       " ('global', 3002),\n",
       " ('warming', 2915),\n",
       " ('ly', 2371),\n",
       " ('bit', 2173),\n",
       " ('the', 1978),\n",
       " ('to', 1682),\n",
       " ('of', 1375)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_d = sorted(token.word_docs.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_d[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of a boost we get with removing stop words.\n",
    "\n",
    "I'll add one preprocession step to remove stopwords using nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = stopwords.words('english') + list(string.punctuation)\n",
    "tokenized_tweets = []\n",
    "for index, tweet in enumerate(tweets):\n",
    "    tokens = [i for i in word_tokenize(tweet.lower()) if i not in stop]\n",
    "    tokenized_tweets.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.513\n",
      "testing score: 0.506\n",
      "(array(['No', 'Yes', 'ambiguous'], dtype=object), array([  41, 2991,   13]))\n"
     ]
    }
   ],
   "source": [
    "top_words = 20000\n",
    "max_words = 25\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tokenized_tweets)\n",
    "X = token.texts_to_sequences(texts=tokenized_tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 3892),\n",
       " ('climate', 3360),\n",
       " ('change', 3207),\n",
       " ('global', 2925),\n",
       " ('warming', 2783),\n",
       " ('...', 1331),\n",
       " ('link', 975),\n",
       " ('rt', 898),\n",
       " (\"'s\", 879),\n",
       " ('via', 522)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_d = sorted(token.word_docs.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_d[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also try stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Tokenize and stem\n",
    "tkr = RegexpTokenizer('[a-zA-Z0-9@]+')\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "tokenized_corpus = []\n",
    "\n",
    "for i, tweet in enumerate(tweets):\n",
    "    tokens = [stemmer.stem(t) for t in tkr.tokenize(tweet) if not t.startswith('@')]\n",
    "    tokenized_corpus.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.514\n",
      "testing score: 0.507\n",
      "(array(['No', 'Yes', 'ambiguous'], dtype=object), array([  57, 2974,   14]))\n"
     ]
    }
   ],
   "source": [
    "top_words = 20000\n",
    "max_words = 30\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tokenized_tweets)\n",
    "X = token.texts_to_sequences(texts=tokenized_tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))\n",
    "print(np.unique(model.predict(X_test),return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 3892),\n",
       " ('climate', 3360),\n",
       " ('change', 3207),\n",
       " ('global', 2925),\n",
       " ('warming', 2783),\n",
       " ('...', 1331),\n",
       " ('link', 975),\n",
       " ('rt', 898),\n",
       " (\"'s\", 879),\n",
       " ('via', 522)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_d = sorted(token.word_docs.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_d[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would eventually like to use TF-IDF to select words in 2-3 length vectors and see if these short vectors can be used to classify sentiment (see last cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.514\n",
      "testing score: 0.507\n"
     ]
    }
   ],
   "source": [
    "top_words = 60\n",
    "max_words = 1\n",
    "test_split = 0.5\n",
    "\n",
    "#convert X to ints\n",
    "token = Tokenizer(num_words=top_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                  lower=True, split=' ', char_level=False, oov_token=None)\n",
    "token.fit_on_texts(texts=tweets)\n",
    "X = token.texts_to_sequences(texts=tweets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,sentiment, test_size=test_split)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', n_jobs=-1, max_iter=1e4,\n",
    "                           C=.0001, penalty='l1')\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"training score: {:.3}\".format(model.score(X_train, Y_train)))\n",
    "print(\"testing score: {:.3}\".format(model.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>1</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate</td>\n",
       "      <td>2</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>change</td>\n",
       "      <td>3</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global</td>\n",
       "      <td>4</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warming</td>\n",
       "      <td>5</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>6</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ly</td>\n",
       "      <td>7</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bit</td>\n",
       "      <td>8</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>9</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>10</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on</td>\n",
       "      <td>12</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>13</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>14</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>15</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt</td>\n",
       "      <td>16</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>link</td>\n",
       "      <td>17</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>18</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "      <td>19</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>via</td>\n",
       "      <td>20</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me</td>\n",
       "      <td>21</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>22</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>by</td>\n",
       "      <td>23</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that</td>\n",
       "      <td>24</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retwt</td>\n",
       "      <td>25</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new</td>\n",
       "      <td>26</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from</td>\n",
       "      <td>27</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>28</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this</td>\n",
       "      <td>29</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>30</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>31</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>32</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "      <td>33</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are</td>\n",
       "      <td>34</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>35</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about</td>\n",
       "      <td>36</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at</td>\n",
       "      <td>37</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as</td>\n",
       "      <td>38</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bill</td>\n",
       "      <td>39</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow</td>\n",
       "      <td>40</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how</td>\n",
       "      <td>41</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcot</td>\n",
       "      <td>42</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>more</td>\n",
       "      <td>43</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oohja</td>\n",
       "      <td>45</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will</td>\n",
       "      <td>46</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we</td>\n",
       "      <td>47</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>48</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy</td>\n",
       "      <td>49</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>50</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>51</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>52</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can</td>\n",
       "      <td>53</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ow</td>\n",
       "      <td>54</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>55</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>56</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>or</td>\n",
       "      <td>57</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has</td>\n",
       "      <td>58</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world</td>\n",
       "      <td>59</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s</td>\n",
       "      <td>60</td>\n",
       "      <td>[Yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  value prediction\n",
       "0     http      1      [Yes]\n",
       "0  climate      2      [Yes]\n",
       "0   change      3      [Yes]\n",
       "0   global      4      [Yes]\n",
       "0  warming      5      [Yes]\n",
       "0      the      6      [Yes]\n",
       "0       ly      7      [Yes]\n",
       "0      bit      8      [Yes]\n",
       "0       to      9      [Yes]\n",
       "0       of     10      [Yes]\n",
       "0        a     11      [Yes]\n",
       "0       on     12      [Yes]\n",
       "0       in     13      [Yes]\n",
       "0       is     14      [Yes]\n",
       "0      and     15      [Yes]\n",
       "0       rt     16      [Yes]\n",
       "0     link     17      [Yes]\n",
       "0      for     18      [Yes]\n",
       "0      com     19      [Yes]\n",
       "0      via     20      [Yes]\n",
       "0       me     21      [Yes]\n",
       "0       it     22      [Yes]\n",
       "0       by     23      [Yes]\n",
       "0     that     24      [Yes]\n",
       "0    retwt     25      [Yes]\n",
       "0      new     26      [Yes]\n",
       "0     from     27      [Yes]\n",
       "0        i     28      [Yes]\n",
       "0     this     29      [Yes]\n",
       "0      you     30      [Yes]\n",
       "0      not     31      [Yes]\n",
       "0     news     32      [Yes]\n",
       "0       be     33      [Yes]\n",
       "0      are     34      [Yes]\n",
       "0     with     35      [Yes]\n",
       "0    about     36      [Yes]\n",
       "0       at     37      [Yes]\n",
       "0       as     38      [Yes]\n",
       "0     bill     39      [Yes]\n",
       "0     snow     40      [Yes]\n",
       "0      how     41      [Yes]\n",
       "0     tcot     42      [Yes]\n",
       "0     more     43      [Yes]\n",
       "0      all     44      [Yes]\n",
       "0    oohja     45      [Yes]\n",
       "0     will     46      [Yes]\n",
       "0       we     47      [Yes]\n",
       "0       no     48      [Yes]\n",
       "0   energy     49      [Yes]\n",
       "0   report     50      [Yes]\n",
       "0  science     51      [Yes]\n",
       "0       us     52      [Yes]\n",
       "0      can     53      [Yes]\n",
       "0       ow     54      [Yes]\n",
       "0    green     55      [Yes]\n",
       "0     have     56      [Yes]\n",
       "0       or     57      [Yes]\n",
       "0      has     58      [Yes]\n",
       "0    world     59      [Yes]\n",
       "0        s     60      [Yes]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "cols = [\"word\", \"value\", \"prediction\"]\n",
    "for val, key in enumerate(token.word_index):\n",
    "    word = key\n",
    "    word_ind = val + 1\n",
    "    word_pred = model.predict(word_ind)\n",
    "    new = pd.DataFrame([[word, word_ind, word_pred]], columns=cols)\n",
    "    df = pd.concat([df, new])\n",
    "    if val == 59:\n",
    "        break\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log odds no\"] = df[\"value\"] * model.coef_[0]\n",
    "df[\"log odds yes\"] = df[\"value\"] * model.coef_[1]\n",
    "df[\"log odds nan\"] = df[\"value\"] * model.coef_[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
