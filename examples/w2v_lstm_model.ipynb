{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import json\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Input, Bidirectional, LSTM, regularizers\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, MaxPooling2D, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change these to match your file paths :)\n",
    "filename = '../../wyns/data/tweet_global_warming.csv' #64,706 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word_vector_model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(txt, vocab=None, replace_char=' ',\n",
    "                max_length=300, pad_out=False,\n",
    "                to_lower=True, reverse = False,\n",
    "                truncate_left=False, encoding=None,\n",
    "                letters_only=False):\n",
    "  \n",
    "    txt = txt.split()\n",
    "    # Remove HTML\n",
    "    # This will keep characters and other symbols\n",
    "    txt = [re.sub(r'http:.*', '', r) for r in txt]\n",
    "    txt = [re.sub(r'https:.*', '', r) for r in txt]\n",
    "    \n",
    "    txt = ( \" \".join(txt))\n",
    "    # Remove non-emoticon punctuation and numbers\n",
    "    txt = re.sub(\"[.,!0-9]\", \" \", txt)\n",
    "    if letters_only: \n",
    "        txt = re.sub(\"[^a-zA-Z]\", \" \", txt)\n",
    "    txt = \" \".join(txt.split())\n",
    "    # store length for multiple comparisons\n",
    "    txt_len = len(txt)\n",
    "\n",
    "    if truncate_left:\n",
    "        txt = txt[-max_length:]\n",
    "    else:\n",
    "        txt = txt[:max_length]\n",
    "    # change case\n",
    "    if to_lower:\n",
    "        txt = txt.lower()\n",
    "    # Reverse order\n",
    "    if reverse:\n",
    "        txt = txt[::-1]\n",
    "    # replace chars\n",
    "    if vocab is not None:\n",
    "        txt = ''.join([c if c in vocab else replace_char for c in txt])\n",
    "    # re-encode text\n",
    "    if encoding is not None:\n",
    "        txt = txt.encode(encoding, errors=\"ignore\")\n",
    "    # pad out if needed\n",
    "    if pad_out and max_length>txt_len:\n",
    "        txt = txt + replace_char * (max_length - txt_len)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a sentence with things :) and a link\n"
     ]
    }
   ],
   "source": [
    "# What does this normalization function look like?\n",
    "clean_text = normalize(\"This is A sentence. with things! 123 :) and a link https://gitub.com\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to balance the distrubtion of sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balance(df):\n",
    "    print(\"Balancing the classes\")\n",
    "    type_counts = df['Sentiment'].value_counts()\n",
    "    min_count = min(type_counts.values)\n",
    "\n",
    "    balanced_df = None\n",
    "    for key in type_counts.keys():\n",
    "\n",
    "        df_sub = df[df['Sentiment']==key].sample(n=min_count, replace=False)\n",
    "        if balanced_df is not None:\n",
    "            balanced_df = balanced_df.append(df_sub)\n",
    "        else:\n",
    "            balanced_df = df_sub\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_sentiment(review):\n",
    "    # Review is coming in as Y/N/NaN\n",
    "    # this then cleans the summary and review and gives it a positive or negative value\n",
    "    norm_text = normalize(review[0])\n",
    "    if review[1] in ('Yes', 'Y'):\n",
    "        return ['positive', norm_text]\n",
    "    elif review[1] in ('No', 'N'):\n",
    "        return ['negative', norm_text]\n",
    "    else:\n",
    "        return ['other', norm_text]\n",
    "    \n",
    "data = []\n",
    "with open(filename, 'r', encoding='latin') as f: \n",
    "    for i,line in enumerate(f):\n",
    "        if i == 0: #skip header while i diagnose\n",
    "            continue\n",
    "        # as we read in, clean\n",
    "        line_data = line.split(\",\")\n",
    "        data.append(review_to_sentiment(line_data))\n",
    "        \n",
    "twitter = pd.DataFrame(data, columns=['Sentiment', 'clean_text'], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>fighting poverty and global warming in africa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>carbon offsets: how a vatican forest failed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>carbon offsets: how a vatican forest failed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>uruguay: tools needed for those most vulnerabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>rt @sejorg: rt @jaymiheimbuch: ocean saltiness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                         clean_text\n",
       "1  positive  fighting poverty and global warming in africa ...\n",
       "2  positive  carbon offsets: how a vatican forest failed to...\n",
       "3  positive  carbon offsets: how a vatican forest failed to...\n",
       "4  positive  uruguay: tools needed for those most vulnerabl...\n",
       "5  positive  rt @sejorg: rt @jaymiheimbuch: ocean saltiness..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this demo lets just keep one and five stars the others are marked 'other\n",
    "twitter = twitter[twitter['Sentiment'].isin(['positive', 'negative'])]\n",
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing the classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_twitter = balance(twitter)\n",
    "len(balanced_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now go from the pandas into lists of text and labels\n",
    "\n",
    "text = balanced_twitter['clean_text'].values\n",
    "labels_0 = pd.get_dummies(balanced_twitter['Sentiment'])  # mapping of the labels with dummies (has headers)\n",
    "labels = labels_0.values # removes the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the Train/test split\n",
    "X_train_, X_test_, Y_train_, Y_test_ = train_test_split(text,labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the data look like?\n",
    "# It is a one-hot encoding of the label, either positive or negative\n",
    "Y_train_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dear global warming people: it is degrees in s ca on / heat on [contents of this message are copyrighted and property of author ]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Now for a simple bidirectional LSTM algorithm we set our feature sizes and train a tokenizer\n",
    "# First we Tokenize and get the data into a form that the model can read - this is BoW\n",
    "# In this cell we are also going to define some of our hyperparameters\n",
    "\n",
    "max_fatures = 2000\n",
    "max_len=300\n",
    "batch_size = 32\n",
    "embed_dim = 300\n",
    "lstm_out = 140\n",
    "\n",
    "dense_out=len(labels[0]) #length of features\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(X_train_)\n",
    "X_train = tokenizer.texts_to_sequences(X_train_)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test_)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1850,    1,    2,  133,   19,   10,  600,   12,  104,  798,   11,\n",
       "        280,   11, 1851,    7,   17,  329,   33, 1852,   13,  799,    7,\n",
       "       1125,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now what does our data look like?\n",
    "# Tokenizer creates a BOW encoding, which is then going to be fed into our Embedding matrix\n",
    "# This will be used by the model to build up a word embedding\n",
    "X_train[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n",
       "       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n",
       "       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n",
       "        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938,\n",
       "        0.375     ,  0.171875  ,  0.21386719, -0.19921875,  0.13085938,\n",
       "       -0.07275391, -0.02819824,  0.11621094,  0.15332031,  0.09082031,\n",
       "        0.06787109, -0.0300293 , -0.16894531, -0.20800781, -0.03710938,\n",
       "       -0.22753906,  0.26367188,  0.012146  ,  0.18359375,  0.31054688,\n",
       "       -0.10791016, -0.19140625,  0.21582031,  0.13183594, -0.03515625,\n",
       "        0.18554688, -0.30859375,  0.04785156, -0.10986328,  0.14355469,\n",
       "       -0.43554688, -0.0378418 ,  0.10839844,  0.140625  , -0.10595703,\n",
       "        0.26171875, -0.17089844,  0.39453125,  0.12597656, -0.27734375,\n",
       "       -0.28125   ,  0.14746094, -0.20996094,  0.02355957,  0.18457031,\n",
       "        0.00445557, -0.27929688, -0.03637695, -0.29296875,  0.19628906,\n",
       "        0.20703125,  0.2890625 , -0.20507812,  0.06787109, -0.43164062,\n",
       "       -0.10986328, -0.2578125 , -0.02331543,  0.11328125,  0.23144531,\n",
       "       -0.04418945,  0.10839844, -0.2890625 , -0.09521484, -0.10351562,\n",
       "       -0.0324707 ,  0.07763672, -0.13378906,  0.22949219,  0.06298828,\n",
       "        0.08349609,  0.02929688, -0.11474609,  0.00534058, -0.12988281,\n",
       "        0.02514648,  0.08789062,  0.24511719, -0.11474609, -0.296875  ,\n",
       "       -0.59375   , -0.29492188, -0.13378906,  0.27734375, -0.04174805,\n",
       "        0.11621094,  0.28320312,  0.00241089,  0.13867188, -0.00683594,\n",
       "       -0.30078125,  0.16210938,  0.01171875, -0.13867188,  0.48828125,\n",
       "        0.02880859,  0.02416992,  0.04736328,  0.05859375, -0.23828125,\n",
       "        0.02758789,  0.05981445, -0.03857422,  0.06933594,  0.14941406,\n",
       "       -0.10888672, -0.07324219,  0.08789062,  0.27148438,  0.06591797,\n",
       "       -0.37890625, -0.26171875, -0.13183594,  0.09570312, -0.3125    ,\n",
       "        0.10205078,  0.03063965,  0.23632812,  0.00582886,  0.27734375,\n",
       "        0.20507812, -0.17871094, -0.31445312, -0.01586914,  0.13964844,\n",
       "        0.13574219,  0.0390625 , -0.29296875,  0.234375  , -0.33984375,\n",
       "       -0.11816406,  0.10644531, -0.18457031, -0.02099609,  0.02563477,\n",
       "        0.25390625,  0.07275391,  0.13574219, -0.00138092, -0.2578125 ,\n",
       "       -0.2890625 ,  0.10107422,  0.19238281, -0.04882812,  0.27929688,\n",
       "       -0.3359375 , -0.07373047,  0.01879883, -0.10986328, -0.04614258,\n",
       "        0.15722656,  0.06689453, -0.03417969,  0.16308594,  0.08642578,\n",
       "        0.44726562,  0.02026367, -0.01977539,  0.07958984,  0.17773438,\n",
       "       -0.04370117, -0.00952148,  0.16503906,  0.17285156,  0.23144531,\n",
       "       -0.04272461,  0.02355957,  0.18359375, -0.41601562, -0.01745605,\n",
       "        0.16796875,  0.04736328,  0.14257812,  0.08496094,  0.33984375,\n",
       "        0.1484375 , -0.34375   , -0.14160156, -0.06835938, -0.14648438,\n",
       "       -0.02844238,  0.07421875, -0.07666016,  0.12695312,  0.05859375,\n",
       "       -0.07568359, -0.03344727,  0.23632812, -0.16308594,  0.16503906,\n",
       "        0.1484375 , -0.2421875 , -0.3515625 , -0.30664062,  0.00491333,\n",
       "        0.17675781,  0.46289062,  0.14257812, -0.25      , -0.25976562,\n",
       "        0.04370117,  0.34960938,  0.05957031,  0.07617188, -0.02868652,\n",
       "       -0.09667969, -0.01281738,  0.05859375, -0.22949219, -0.1953125 ,\n",
       "       -0.12207031,  0.20117188, -0.42382812,  0.06005859,  0.50390625,\n",
       "        0.20898438,  0.11230469, -0.06054688,  0.33203125,  0.07421875,\n",
       "       -0.05786133,  0.11083984, -0.06494141,  0.05639648,  0.01757812,\n",
       "        0.08398438,  0.13769531,  0.2578125 ,  0.16796875, -0.16894531,\n",
       "        0.01794434,  0.16015625,  0.26171875,  0.31640625, -0.24804688,\n",
       "        0.05371094, -0.0859375 ,  0.17089844, -0.39453125, -0.00156403,\n",
       "       -0.07324219, -0.04614258, -0.16210938, -0.15722656,  0.21289062,\n",
       "       -0.15820312,  0.04394531,  0.28515625,  0.01196289, -0.26953125,\n",
       "       -0.04370117,  0.37109375,  0.04663086, -0.19726562,  0.3046875 ,\n",
       "       -0.36523438, -0.23632812,  0.08056641, -0.04248047, -0.14648438,\n",
       "       -0.06225586, -0.0534668 , -0.05664062,  0.18945312,  0.37109375,\n",
       "       -0.22070312,  0.04638672,  0.02612305, -0.11474609,  0.265625  ,\n",
       "       -0.02453613,  0.11083984, -0.02514648, -0.12060547,  0.05297852,\n",
       "        0.07128906,  0.00063705, -0.36523438, -0.13769531, -0.12890625], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a word vector look like?\n",
    "# Ahhhh, like a bunch of numbers\n",
    "word_vector_model.word_vec('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the embedding matrix\n"
     ]
    }
   ],
   "source": [
    "print('Prepare the embedding matrix')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(max_fatures, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_len:\n",
    "        continue\n",
    "    # words not found in embedding index will be all-zeros.\n",
    "    if word in word_vector_model.vocab:\n",
    "        embedding_matrix[i] = word_vector_model.word_vec(word)\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = True to fine tune the embeddings\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embed_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_fatures,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08056641, -0.04296875, -0.09716797,  0.10107422, -0.20507812,\n",
       "       -0.03833008,  0.04541016, -0.30078125,  0.10791016, -0.04248047,\n",
       "       -0.25976562, -0.09765625,  0.16796875, -0.1484375 , -0.10449219,\n",
       "       -0.05541992, -0.01519775,  0.12255859,  0.0534668 , -0.03881836,\n",
       "       -0.328125  , -0.006073  , -0.00241089, -0.16992188,  0.10400391,\n",
       "        0.00148773, -0.0625    , -0.09814453,  0.1640625 , -0.06738281,\n",
       "       -0.02612305, -0.16992188, -0.06933594, -0.08984375,  0.15136719,\n",
       "       -0.01721191, -0.01794434,  0.02038574,  0.14941406,  0.02099609,\n",
       "       -0.02453613, -0.01556396,  0.03588867,  0.15527344,  0.03515625,\n",
       "        0.1328125 , -0.06298828,  0.03613281,  0.09716797,  0.20117188,\n",
       "       -0.0291748 ,  0.03637695, -0.22363281,  0.03710938,  0.26953125,\n",
       "        0.16992188, -0.05639648, -0.16796875,  0.20996094, -0.08837891,\n",
       "       -0.10986328,  0.08007812,  0.08984375,  0.11621094,  0.08154297,\n",
       "       -0.04345703,  0.05053711,  0.01251221,  0.18554688, -0.00756836,\n",
       "       -0.28125   ,  0.12451172,  0.28515625,  0.15917969,  0.00102997,\n",
       "       -0.07275391,  0.07666016,  0.23925781, -0.02893066, -0.14453125,\n",
       "       -0.03588867, -0.06933594, -0.18457031,  0.04711914,  0.08349609,\n",
       "        0.08105469, -0.11425781,  0.11279297, -0.07568359,  0.20019531,\n",
       "        0.37109375, -0.31445312, -0.16113281,  0.01611328, -0.12304688,\n",
       "       -0.1796875 ,  0.00741577, -0.16113281,  0.38867188, -0.01635742,\n",
       "       -0.19921875,  0.19726562, -0.01306152,  0.17773438, -0.234375  ,\n",
       "       -0.02087402, -0.22753906, -0.00241089, -0.02148438, -0.02380371,\n",
       "       -0.06591797, -0.13183594, -0.27929688, -0.06103516,  0.06787109,\n",
       "        0.04956055, -0.22070312, -0.21875   ,  0.34765625,  0.15625   ,\n",
       "       -0.1953125 , -0.15625   , -0.09521484,  0.11572266, -0.15136719,\n",
       "        0.03833008,  0.04150391, -0.12988281, -0.01452637,  0.15136719,\n",
       "        0.06640625,  0.24902344, -0.12304688,  0.0480957 , -0.09619141,\n",
       "       -0.02905273,  0.17382812, -0.07226562, -0.08837891, -0.06030273,\n",
       "        0.2578125 , -0.12890625,  0.046875  ,  0.00952148,  0.11279297,\n",
       "       -0.10742188,  0.22753906,  0.1328125 ,  0.10693359, -0.11230469,\n",
       "        0.16796875, -0.15917969, -0.02770996,  0.03613281, -0.01287842,\n",
       "       -0.06396484, -0.09521484,  0.01330566,  0.1328125 , -0.18164062,\n",
       "       -0.07275391, -0.234375  , -0.00148773, -0.140625  ,  0.11572266,\n",
       "        0.04638672,  0.04321289, -0.23925781,  0.01202393,  0.14355469,\n",
       "       -0.00738525, -0.00366211,  0.2734375 , -0.15136719,  0.08251953,\n",
       "       -0.26367188,  0.01049805, -0.03930664, -0.24609375, -0.12792969,\n",
       "       -0.09472656,  0.00946045,  0.15039062, -0.25195312,  0.19726562,\n",
       "        0.04516602, -0.00144196, -0.02233887,  0.07373047,  0.29882812,\n",
       "       -0.20996094, -0.14648438, -0.21289062, -0.21582031, -0.25390625,\n",
       "        0.04858398, -0.0859375 , -0.19433594,  0.11914062, -0.40820312,\n",
       "       -0.11962891, -0.08789062,  0.09423828,  0.03063965,  0.06298828,\n",
       "        0.15722656,  0.203125  , -0.11181641, -0.19824219,  0.00267029,\n",
       "       -0.21289062, -0.04199219,  0.00126648,  0.3046875 ,  0.04199219,\n",
       "       -0.01080322, -0.04931641, -0.07177734, -0.07080078,  0.18652344,\n",
       "       -0.07373047,  0.02392578, -0.00265503,  0.01940918, -0.16894531,\n",
       "       -0.02832031,  0.02832031, -0.25585938,  0.11083984, -0.00549316,\n",
       "       -0.22949219,  0.00300598,  0.28710938, -0.22558594, -0.10058594,\n",
       "        0.03295898, -0.07958984,  0.11523438, -0.06738281, -0.10839844,\n",
       "        0.08056641,  0.03564453, -0.14941406,  0.07128906, -0.0456543 ,\n",
       "       -0.04296875,  0.04760742, -0.18457031, -0.05249023, -0.27148438,\n",
       "        0.04467773, -0.03015137, -0.14941406,  0.01062012,  0.02453613,\n",
       "       -0.24707031,  0.2109375 , -0.14648438,  0.02038574, -0.11865234,\n",
       "       -0.08544922, -0.20117188,  0.01348877, -0.02392578,  0.13769531,\n",
       "        0.18457031, -0.19726562, -0.04223633, -0.09179688,  0.11230469,\n",
       "       -0.16601562,  0.04223633,  0.0279541 , -0.23925781,  0.01177979,\n",
       "       -0.00123596, -0.13671875,  0.18847656,  0.11621094,  0.19628906,\n",
       "       -0.11865234, -0.11230469, -0.01184082, -0.10888672,  0.12353516,\n",
       "        0.3203125 , -0.18457031,  0.0378418 ,  0.12792969, -0.00396729,\n",
       "        0.0402832 ,  0.05786133, -0.0534668 ,  0.15234375, -0.03637695,\n",
       "        0.01647949,  0.05175781,  0.36914062,  0.14746094, -0.12792969])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2000, 300)         600000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 280)               493920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 562       \n",
      "=================================================================\n",
      "Total params: 1,094,482\n",
      "Trainable params: 1,094,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model using the pre-trained embedding\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(lstm_out, recurrent_dropout=0.5, activation='tanh'))(embedded_sequences)\n",
    "preds = Dense(dense_out, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1257 samples, validate on 315 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 0.6444 - acc: 0.6301 - val_loss: 0.5711 - val_acc: 0.7079\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.4592 - acc: 0.7963 - val_loss: 0.4180 - val_acc: 0.8476\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.3104 - acc: 0.8703 - val_loss: 0.4393 - val_acc: 0.7937\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.2068 - acc: 0.9260 - val_loss: 0.4092 - val_acc: 0.8159\n",
      "Epoch 5/20\n",
      " - 19s - loss: 0.1470 - acc: 0.9467 - val_loss: 0.5448 - val_acc: 0.8000\n",
      "Epoch 6/20\n",
      " - 20s - loss: 0.1073 - acc: 0.9578 - val_loss: 0.5026 - val_acc: 0.8032\n",
      "Epoch 7/20\n",
      " - 18s - loss: 0.0914 - acc: 0.9690 - val_loss: 0.6580 - val_acc: 0.8063\n",
      "Epoch 8/20\n",
      " - 18s - loss: 0.0668 - acc: 0.9769 - val_loss: 0.6822 - val_acc: 0.8159\n",
      "Epoch 9/20\n",
      " - 18s - loss: 0.0600 - acc: 0.9793 - val_loss: 0.6853 - val_acc: 0.8095\n",
      "Epoch 10/20\n",
      " - 18s - loss: 0.0585 - acc: 0.9745 - val_loss: 0.7303 - val_acc: 0.8063\n",
      "Epoch 11/20\n",
      " - 19s - loss: 0.0534 - acc: 0.9817 - val_loss: 0.7025 - val_acc: 0.7968\n",
      "Epoch 12/20\n",
      " - 19s - loss: 0.0452 - acc: 0.9801 - val_loss: 0.8359 - val_acc: 0.8000\n",
      "Epoch 13/20\n",
      " - 18s - loss: 0.0441 - acc: 0.9801 - val_loss: 0.8490 - val_acc: 0.8032\n",
      "Epoch 14/20\n",
      " - 18s - loss: 0.0377 - acc: 0.9833 - val_loss: 0.8982 - val_acc: 0.8127\n",
      "Epoch 15/20\n",
      " - 18s - loss: 0.0319 - acc: 0.9881 - val_loss: 1.1313 - val_acc: 0.7810\n",
      "Epoch 16/20\n",
      " - 18s - loss: 0.0501 - acc: 0.9777 - val_loss: 0.8279 - val_acc: 0.7873\n",
      "Epoch 17/20\n",
      " - 18s - loss: 0.0400 - acc: 0.9833 - val_loss: 0.8264 - val_acc: 0.7968\n",
      "Epoch 18/20\n",
      " - 18s - loss: 0.0298 - acc: 0.9865 - val_loss: 0.9463 - val_acc: 0.8000\n",
      "Epoch 19/20\n",
      " - 18s - loss: 0.0265 - acc: 0.9873 - val_loss: 0.8794 - val_acc: 0.8063\n",
      "Epoch 20/20\n",
      " - 18s - loss: 0.0328 - acc: 0.9849 - val_loss: 0.9290 - val_acc: 0.8127\n"
     ]
    }
   ],
   "source": [
    "model_hist_embedding = model.fit(X_train, Y_train_, epochs = 20, batch_size=batch_size, verbose = 2,\n",
    "                        validation_data=(X_test,Y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff37f69f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "x = np.arange(20)+1\n",
    "\n",
    "plt.plot(x, model_hist_embedding.history['acc'])\n",
    "plt.plot(x, model_hist_embedding.history['val_acc'])\n",
    "plt.legend(['Training', 'Testing'], loc='lower right')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.45,1.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"LSTM Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_hist_embedding.model.save(\"../../wyns/data/climate_sentiment_m2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
